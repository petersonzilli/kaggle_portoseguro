{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porto Seguroâ€™s Safe Driver Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got Felipe Antunes code as a startpack: https://github.com/felipeeeantunes/udacity_live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import gc\n",
    "from time import time\n",
    "from multiprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'png')\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "rc={'savefig.dpi': 75, 'figure.autolayout': False, 'figure.figsize': [12, 8], 'axes.labelsize': 18,\\\n",
    "   'axes.titlesize': 18, 'font.size': 18, 'lines.linewidth': 2.0, 'lines.markersize': 8, 'legend.fontsize': 16,\\\n",
    "   'xtick.labelsize': 16, 'ytick.labelsize': 16}\n",
    "\n",
    "sns.set(style='dark',rc=rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_color = '#56B4E9'\n",
    "colormap = plt.cm.cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting working directory\n",
    "path = '../data/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "del train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_train = train['id'].values\n",
    "id_test = test['id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_original = list(train.columns)\n",
    "columns_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming -1 'null's in np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.replace(-1, np.NaN)\n",
    "test = test.replace(-1, np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "ax = sns.countplot(x=y, color=default_color)\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.2f}%'.format(100*p.get_height()/len(y)), (p.get_x()+ 0.3, p.get_height()+10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_meta(train):\n",
    "    data = []\n",
    "    for col in train.columns:\n",
    "        # Defining the role\n",
    "        if col == 'target':\n",
    "            role = 'target'\n",
    "        elif col == 'id':\n",
    "            role = 'id'\n",
    "        else:\n",
    "            role = 'input'\n",
    "\n",
    "        # Defining the level\n",
    "        if 'bin' in col or col == 'target':\n",
    "            level = 'binary'\n",
    "        elif 'cat' in col or col == 'id':\n",
    "            level = 'nominal'\n",
    "        elif train[col].dtype == np.float64:\n",
    "            level = 'interval'\n",
    "        elif train[col].dtype == np.int64:\n",
    "            level = 'ordinal'\n",
    "\n",
    "        # Initialize keep to True for all variables except for id\n",
    "        keep = True\n",
    "        if col == 'id':\n",
    "            keep = False\n",
    "\n",
    "        # Defining the data type \n",
    "        dtype = train[col].dtype\n",
    "\n",
    "        source = 'id'\n",
    "        if '_ind_' in col:\n",
    "            source = 'ind'\n",
    "        if '_reg_' in col:\n",
    "            source = 'reg'\n",
    "        elif '_car_' in col:\n",
    "            source = 'car'\n",
    "        elif '_calc_' in col:\n",
    "            source = 'calc'\n",
    "        \n",
    "        # Creating a Dict that contains all the metadata for the variable\n",
    "        col_dict = {\n",
    "            'varname': col,\n",
    "            'role'   : role,\n",
    "            'level'  : level,\n",
    "            'keep'   : keep,\n",
    "            'dtype'  : dtype,\n",
    "            'source' : source\n",
    "        }\n",
    "        data.append(col_dict)\n",
    "    meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype', 'source'])\n",
    "    meta.set_index('varname', inplace=True)\n",
    "    return meta\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = get_meta(train)\n",
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_counts = meta_data.groupby(['role', 'level']).agg({'dtype': lambda x: x.count()}).reset_index()\n",
    "meta_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "fig.set_size_inches(7,5)\n",
    "sns.barplot(data=meta_counts[(meta_counts.role != 'target') & (meta_counts.role != 'id') ],x=\"level\",y=\"dtype\",ax=ax,color=default_color)\n",
    "ax.set(xlabel='Variable Type', ylabel='Count',title=\"Variables Count Across Datatype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_ordinal   = meta_data[(meta_data.level == 'ordinal') & (meta_data.keep)].index\n",
    "col_nominal   = meta_data[(meta_data.level == 'nominal') & (meta_data.keep)].index\n",
    "col_internval = meta_data[(meta_data.level == 'interval') & (meta_data.keep)].index\n",
    "col_binary    = meta_data[(meta_data.level == 'binary') & (meta_data.keep) & (meta_data.role != 'target')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(train[columns_original],figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingValueColumns = train.columns[train.isnull().any()].tolist()\n",
    "df_null = train[missingValueColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df_null,figsize=(20,8),color=default_color,fontsize=18,labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(df_null,figsize=(10,10),cmap=colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(df_null,figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = msno.nullity_sort(df_null, sort='descending') # or sort='ascending'\n",
    "msno.matrix(sorted_data,figsize=(20,8),fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,16))\n",
    "plt.title('Pearson correlation of continuous features', y=1.05, size=15)\n",
    "sns.heatmap(train[col_internval].corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use -1 instead of NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Baseline RF Model and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_rf_featimp = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 10,\n",
    "    'max_features': 0.2,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_featimp = RandomForestClassifier(**conf_rf_featimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "rf_featimp.fit(train, y)\n",
    "print(\"----- Training Time: %  secs. -----\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = columns_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_importance_df(feature_importances, \n",
    "                              column_names, \n",
    "                              top_n=25):\n",
    "    \"\"\"Get feature importance data frame.\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_importances : numpy ndarray\n",
    "        Feature importances computed by an ensemble \n",
    "            model like random forest or boosting\n",
    "    column_names : array-like\n",
    "        Names of the columns in the same order as feature \n",
    "            importances\n",
    "    top_n : integer\n",
    "        Number of top features\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    df : a Pandas data frame\n",
    " \n",
    "    \"\"\"\n",
    "     \n",
    "    imp_dict = dict(zip(column_names, \n",
    "                        feature_importances))\n",
    "    top_features = sorted(imp_dict, \n",
    "                          key=imp_dict.get, \n",
    "                          reverse=True)[0:top_n]\n",
    "    top_importances = [imp_dict[feature] for feature \n",
    "                          in top_features]\n",
    "    df = pd.DataFrame(data={'feature': top_features, \n",
    "                            'importance': top_importances})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = get_feature_importance_df(rf_featimp.feature_importances_, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "g=sns.barplot(data=feature_importance,x=\"feature\",y=\"importance\",ax=ax,color=default_color,)\n",
    "for item in g.get_xticklabels():\n",
    "    item.set_rotation(45)\n",
    "ax.set(xlabel='Variable name', ylabel='Importance',title=\"Variable importances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Val function and Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val_model(X, y, model, n_splits=3):\n",
    "   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    folds = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42).split(X, y))\n",
    "\n",
    "    cross_score_mean = 0.0\n",
    "\n",
    "    t0 = time()\n",
    "    \n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_holdout = X[test_idx]\n",
    "        y_holdout = y[test_idx]\n",
    "\n",
    "        print (\"Fit %s fold %d\" % (str(model).split('(')[0], j+1))\n",
    "        model.fit(X_train, y_train)\n",
    "        cross_score = cross_val_score(model, X_holdout, y_holdout, cv=3, scoring='roc_auc')\n",
    "        print(\"    cross_score: %.5f (%.5f)\" % (cross_score.mean(), cross_score.mean()*2-1)) \n",
    "        print(\"    [%10d secs elapsed]: cross_score: %.5f (%.5f)\" % (time()-t0, cross_score.mean(), cross_score.mean()*2-1)) \n",
    "        cross_score_mean += cross_score.mean()\n",
    "        \n",
    "    cross_score_mean /= n_splits\n",
    "    print(\"cross_score_mean: %.5f (%.5f)\" % (cross_score_mean, cross_score_mean*2-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Val - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_rf_model = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 70,\n",
    "    'min_samples_leaf': 30,\n",
    "    'n_jobs': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(**conf_rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_model(train, y, rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Val - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters from https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283/code\n",
    "conf_xgb_model = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 1,\n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 1,\n",
    "    'nthread': 2,\n",
    "    'min_child_weight': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(**conf_xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_model(train, y, xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Val - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_lgb_model = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'learning_rate': 0.05,\n",
    "    'sub_feature': 0.8,\n",
    "    'num_leaves': 20,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_model = LGBMClassifier(**conf_lgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_val_model(train, y, lgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering & Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selected features from https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283/code\n",
    "selected_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "    \"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "    \"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "    \"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "    \"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "    \"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "    \"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "    \"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "    \"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "    \"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "    \"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "    \"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "    \"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "    \"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "    \"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "    \"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "    \"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "    \"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "    \"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "    \"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "    \"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "    \"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "    \"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "    \"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "    \"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "    \"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "    \"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "    \"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "    \"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "    \"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "    \"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "    \"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "    \"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "    \"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "    \"ps_car_11_cat\" # Very nice spot from Tilii : https://www.kaggle.com/tilii7\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, lgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add combinations from https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283/code\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]\n",
    "start = time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f' % (name1, n_c + 1, (time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    train[name1] = train[f1].apply(lambda x: str(x)) + \"_\" + train[f2].apply(lambda x: str(x))\n",
    "    test[name1] = test[f1].apply(lambda x: str(x)) + \"_\" + test[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train[name1].values) + list(test[name1].values))\n",
    "    train[name1] = lbl.transform(list(train[name1].values))\n",
    "    test[name1] = lbl.transform(list(test[name1].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = [f1 + '_plus_' + f2 for (f1, f2) in combs]\n",
    "selected_features.extend(new_features)\n",
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, lgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructing ps_reg_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### from Pascal's (https://www.kaggle.com/pnagel/reconstruction-of-ps-reg-03)\n",
    "def recon(reg):\n",
    "    integer = int(np.round((40*reg)**2)) \n",
    "    for a in range(32):\n",
    "        if (integer - a) % 31 == 0:\n",
    "            A = a\n",
    "    M = (integer - A)//31\n",
    "    return A, M\n",
    "\n",
    "train['ps_reg_A'] = train['ps_reg_03'].apply(lambda x: recon(x)[0] )\n",
    "train['ps_reg_M'] = train['ps_reg_03'].apply(lambda x: recon(x)[1])\n",
    "train['ps_reg_A'].replace(19, -1, inplace=True) # replace -1 with np.NaN\n",
    "train['ps_reg_M'].replace(51, -1, inplace=True) # replace -1 with np.NaN\n",
    "\n",
    "test['ps_reg_A'] = test['ps_reg_03'].apply(lambda x: recon(x)[0])\n",
    "test['ps_reg_M'] = test['ps_reg_03'].apply(lambda x: recon(x)[1])\n",
    "test['ps_reg_A'].replace(19, np.NaN, inplace=True) # replace -1 with np.NaN\n",
    "test['ps_reg_M'].replace(51, np.NaN, inplace=True) # replace -1 with np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_features = ['ps_reg_A', 'ps_reg_M']\n",
    "selected_features.extend(new_features)\n",
    "selected_features.remove('ps_reg_03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, lgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['ps_reg_A', 'ps_reg_M']: selected_features.remove(x)\n",
    "selected_features.append('ps_reg_03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One HOT and Categorical Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.replace(-1, np.NaN)\n",
    "test = test.replace(-1, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = {c: len(list(train[c].unique())) for c in selected_features}\n",
    "sorted( ((v,k) for k,v in one_hot.items()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_lt_than_5_unique = { k:v for k, v in one_hot.items() if v < 5 }\n",
    "one_hot_me_than_5_unique = { k:v for k, v in one_hot.items() if v >= 5}\n",
    "one_hot_me_than_5_unique_cat = { k:v for k, v in one_hot.items() if v >= 5 and 'cat' in k}\n",
    "one_hot_lt_than_5_unique, one_hot_me_than_5_unique, one_hot_me_than_5_unique_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE_by_unique(train, one_hot, limit):\n",
    "    \n",
    "    #ONE-HOT enconde features with more than 2 and less than 'limit' unique values\n",
    "    df = train.copy()\n",
    "    for c in one_hot.keys():\n",
    "        if len(one_hot[c]) > 2 and len(one_hot[c]) <= limit:\n",
    "            for val in one_hot[c]:\n",
    "                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)\n",
    "            print(c)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_values = {c: list(train[c].unique()) for c in selected_features}\n",
    "list(one_hot_values.items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([14, 5, 850, 3, 3, 100, 2, 2, 2, 8, 5, 2, 2, 18, 13, 5, 6, 10, 7, 12, 2, 19, 5013, 24, 184, 8, 10, 8, 15, 3, 2, 3, 2, 104, 2, 3, 70482])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_train = OHE_by_unique(train, one_hot_values, 3)\n",
    "oh_test = OHE_by_unique(test, one_hot_values, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_onehotted_columns = ['ps_car_03_cat','ps_car_07_cat','ps_car_02_cat','ps_ind_04_cat','ps_car_05_cat','ps_car_03_cat','ps_car_07_cat','ps_car_02_cat','ps_ind_04_cat','ps_car_05_cat']\n",
    "selected_features_oh = selected_features.copy()\n",
    "selected_features_oh, oh_onehotted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in oh_onehotted_columns:\n",
    "    if c in selected_features_oh:\n",
    "        selected_features_oh.remove(c)\n",
    "oh_columns = [c for c in oh_train.columns if c in selected_features or '_oh_' in c]\n",
    "print(oh_columns)\n",
    "selected_features_oh.extend(oh_columns)\n",
    "print(selected_features_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_train = oh_train.fillna(-1)\n",
    "oh_test = oh_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_val_model(oh_train[selected_features], y, rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_model(oh_train[selected_features], y, xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit LGBMClassifier fold 1\n"
     ]
    }
   ],
   "source": [
    "cross_val_model(oh_train[selected_features], y, lgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_val_model(train[selected_features], y, lgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_cats = [f for f in trn_df.columns if \"_cat\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in f_cats:\n",
    "    trn_df[f + \"_avg\"], sub_df[f + \"_avg\"] = target_encode(trn_series=trn_df[f],\n",
    "                                         tst_series=sub_df[f],\n",
    "                                         target=target,\n",
    "                                         min_samples_leaf=200,\n",
    "                                         smoothing=10,\n",
    "                                         noise_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
